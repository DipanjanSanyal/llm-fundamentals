{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53bef656",
   "metadata": {
    "papermill": {
     "duration": 0.004715,
     "end_time": "2025-04-10T13:11:38.552864",
     "exception": false,
     "start_time": "2025-04-10T13:11:38.548149",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* **Previous Notebook in series**: LLM Fundamentals 3\n",
    "\n",
    "* **This Notebook**: Training with LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27b1b469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dipanjansanyal/Documents/llm-fundamentals/llm-fundamentals/env/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82899a7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T13:11:38.562124Z",
     "iopub.status.busy": "2025-04-10T13:11:38.561867Z",
     "iopub.status.idle": "2025-04-10T13:11:38.568994Z",
     "shell.execute_reply": "2025-04-10T13:11:38.568245Z"
    },
    "papermill": {
     "duration": 0.013661,
     "end_time": "2025-04-10T13:11:38.570687",
     "exception": false,
     "start_time": "2025-04-10T13:11:38.557026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Experiment Configuration\n",
    "context_length = 10\n",
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "response_tokens = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d39e548",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T13:11:50.855473Z",
     "iopub.status.busy": "2025-04-10T13:11:50.855179Z",
     "iopub.status.idle": "2025-04-10T13:11:56.601579Z",
     "shell.execute_reply": "2025-04-10T13:11:56.600627Z"
    },
    "papermill": {
     "duration": 5.753672,
     "end_time": "2025-04-10T13:11:56.603290",
     "exception": false,
     "start_time": "2025-04-10T13:11:50.849618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x12800f530>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import tokenmonster\n",
    "import more_itertools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import pad\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6dad121",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T13:11:56.614262Z",
     "iopub.status.busy": "2025-04-10T13:11:56.613863Z",
     "iopub.status.idle": "2025-04-10T13:11:56.686052Z",
     "shell.execute_reply": "2025-04-10T13:11:56.685232Z"
    },
    "papermill": {
     "duration": 0.07939,
     "end_time": "2025-04-10T13:11:56.687636",
     "exception": false,
     "start_time": "2025-04-10T13:11:56.608246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Check if MPS is available and use it if available\n",
    "\n",
    "# if torch.backends.mps.is_available():\n",
    "#     device = torch.device(\"mps\")\n",
    "# else:\n",
    "#     device = torch.device(\"cpu\")\n",
    "\n",
    "# print(device)\n",
    "\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4575ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (288, 1)\n",
      "Dataset columns: Index(['text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Reading the dataset\n",
    "dataset = pd.read_csv(\"./data/cefr_leveled_texts.csv\", index_col=0)\n",
    "dataset = dataset.query('label == \"A1\"').reset_index() # Selecting easiest level\n",
    "# Deduplicate repeated headlines\n",
    "dataset = dataset.filter(['text']).drop_duplicates()\n",
    "print(\"Dataset shape:\", dataset.shape)\n",
    "print(\"Dataset columns:\", dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bcc8b06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T13:12:03.770355Z",
     "iopub.status.busy": "2025-04-10T13:12:03.769640Z",
     "iopub.status.idle": "2025-04-10T13:12:04.215538Z",
     "shell.execute_reply": "2025-04-10T13:12:04.214715Z"
    },
    "papermill": {
     "duration": 0.453084,
     "end_time": "2025-04-10T13:12:04.217067",
     "exception": false,
     "start_time": "2025-04-10T13:12:03.763983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2049"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading pre-trained tokenizer and adding special tokens\n",
    "tokenizer = tokenmonster.load(\"english-2048-consistent-v1\")\n",
    "tokenizer.add_special_token('<pad>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f532d61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T13:12:04.228329Z",
     "iopub.status.busy": "2025-04-10T13:12:04.227619Z",
     "iopub.status.idle": "2025-04-10T13:12:04.239029Z",
     "shell.execute_reply": "2025-04-10T13:12:04.238063Z"
    },
    "papermill": {
     "duration": 0.018842,
     "end_time": "2025-04-10T13:12:04.240819",
     "exception": false,
     "start_time": "2025-04-10T13:12:04.221977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 2049\n",
      "Testing tokenizer: [ 182  869 1680  852 1002  217  420 1540    4  104 1386 1222 1144    3]\n",
      "Testing tokenizer: You need to try harder in school!\n",
      "I am doing well \n",
      "182 :  \n",
      "869 :   you\n",
      "1680 :   need to\n",
      "852 :   try\n",
      "1002 :   hard\n",
      "217 :  er\n",
      "420 :   in\n",
      "1540 :   school\n",
      "4 :  !\n",
      "104 :  \n",
      "\n",
      "1386 :   I am\n",
      "1222 :   doing\n",
      "1144 :   well\n",
      "3 :   \n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary Size:\", tokenizer.vocab_size)\n",
    "token_ids = tokenizer.tokenize(dataset.text[0][0:50])\n",
    "print(\"Testing tokenizer:\", token_ids)\n",
    "print(\"Testing tokenizer:\", tokenizer.decoder().decode(token_ids))\n",
    "for i in token_ids:\n",
    "    print(i, \": \", tokenizer.decoder().decode(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ce8d33",
   "metadata": {
    "papermill": {
     "duration": 0.004587,
     "end_time": "2025-04-10T13:12:04.250367",
     "exception": false,
     "start_time": "2025-04-10T13:12:04.245780",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "608175b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T13:12:04.261422Z",
     "iopub.status.busy": "2025-04-10T13:12:04.260833Z",
     "iopub.status.idle": "2025-04-10T13:12:50.482169Z",
     "shell.execute_reply": "2025-04-10T13:12:50.481458Z"
    },
    "papermill": {
     "duration": 46.22916,
     "end_time": "2025-04-10T13:12:50.484269",
     "exception": false,
     "start_time": "2025-04-10T13:12:04.255109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_of_sentences = list(dataset['text'])\n",
    "\n",
    "# Divide each tokenized sentence into expanding window with preset max length (content length = 10)\n",
    "# Store them as a list of tensors, so that the collate_fn of DataLoader can source them\n",
    "# They are stored as a list rather than an array because they are of different sizes tensors (size 2 to 10)\n",
    "\n",
    "data = []\n",
    "for sentence in list_of_sentences:\n",
    "\n",
    "    sentence_tokens = tokenizer.tokenize(sentence)\n",
    "    l = len(sentence_tokens)\n",
    "    applicable_context_length = min(l, context_length)    \n",
    "\n",
    "    counter_t = []\n",
    "    for t in range(2,applicable_context_length+1):        \n",
    "\n",
    "        expanding_tuples = more_itertools.windowed(sentence_tokens, t)\n",
    "        data_t = [torch.tensor(item).to(torch.long) for item in list(expanding_tuples)]\n",
    "        counter_t.extend(data_t)     \n",
    "\n",
    "    data.extend(counter_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1938e8b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T13:12:50.495857Z",
     "iopub.status.busy": "2025-04-10T13:12:50.495568Z",
     "iopub.status.idle": "2025-04-10T13:12:50.499424Z",
     "shell.execute_reply": "2025-04-10T13:12:50.498756Z"
    },
    "papermill": {
     "duration": 0.010937,
     "end_time": "2025-04-10T13:12:50.500876",
     "exception": false,
     "start_time": "2025-04-10T13:12:50.489939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the variable sized sequences into train test\n",
    "train, test = train_test_split(data, test_size = 0.2, random_state = 123)\n",
    "\n",
    "# Create a collate function which performs the following operation under each batch when the batch is called\n",
    "# For each item inside a batch, it splits input and target sequence\n",
    "# Then it pads them to match tensors of (context_length - 1)\n",
    "padding_token = tokenizer.tokenize('<pad>').item()\n",
    "def collate_fn(batch):\n",
    "    # Separate the inputs and targets (target is 1 token shifted right)\n",
    "    inputs = [item[:-1] for item in batch]\n",
    "    targets = [item[1:] for item in batch]\n",
    "    \n",
    "    # Pad the sequences to the same length i.e. (context_length - 1)\n",
    "    inputs = [pad(item, (0, context_length-1-len(item)), value = padding_token) for item in inputs]\n",
    "    targets = [pad(item, (0, context_length-1-len(item)), value = padding_token) for item in targets]\n",
    "\n",
    "    # convert them to form 2D tensor of shape (B x T)\n",
    "    inputs = torch.stack(inputs).to(device)\n",
    "    targets = torch.stack(targets).to(device)\n",
    "    \n",
    "    return inputs, targets\n",
    "\n",
    "# Define the data loader with preset batch size and predefined collate_fn\n",
    "train_loader = DataLoader(train, batch_size = batch_size, shuffle = True, drop_last = True, collate_fn = collate_fn)\n",
    "test_loader = DataLoader(test, batch_size = batch_size, shuffle = False, drop_last = True, collate_fn = collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9966cd74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T13:12:50.511650Z",
     "iopub.status.busy": "2025-04-10T13:12:50.511398Z",
     "iopub.status.idle": "2025-04-10T13:12:50.518114Z",
     "shell.execute_reply": "2025-04-10T13:12:50.517131Z"
    },
    "papermill": {
     "duration": 0.013993,
     "end_time": "2025-04-10T13:12:50.519701",
     "exception": false,
     "start_time": "2025-04-10T13:12:50.505708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  tensor([[ 737,  214,   15, 1609, 1274,  287, 2048, 2048, 2048],\n",
      "        [ 842,  828,   51, 2048, 2048, 2048, 2048, 2048, 2048],\n",
      "        [ 400,   69,  873, 1770, 2048, 2048, 2048, 2048, 2048],\n",
      "        [1025, 1119, 1182,  869,  873, 1367, 1011, 1167, 2048],\n",
      "        [  63,  873, 1828,  328,  667,   58, 2048, 2048, 2048]])\n",
      "y:  tensor([[ 214,   15, 1609, 1274,  287,  329, 2048, 2048, 2048],\n",
      "        [ 828,   51, 1615, 2048, 2048, 2048, 2048, 2048, 2048],\n",
      "        [  69,  873, 1770, 1813, 2048, 2048, 2048, 2048, 2048],\n",
      "        [1119, 1182,  869,  873, 1367, 1011, 1167, 1771, 2048],\n",
      "        [ 873, 1828,  328,  667,   58,   58, 2048, 2048, 2048]])\n"
     ]
    }
   ],
   "source": [
    "# How did we form this?\n",
    "\n",
    "x,y = next(iter(train_loader))\n",
    "print(\"x: \", x[:5])\n",
    "print(\"y: \", y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdaa7e2",
   "metadata": {
    "papermill": {
     "duration": 0.004779,
     "end_time": "2025-04-10T13:12:50.604182",
     "exception": false,
     "start_time": "2025-04-10T13:12:50.599403",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3eb23b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token and positional embeddings\n",
    "token_embedding = nn.Embedding(2049, 128, padding_idx = padding_token)\n",
    "fx = token_embedding(x)\n",
    "\n",
    "position_embedding = nn.Embedding(context_length-1, 128)\n",
    "\n",
    "pos_indices = torch.arange(context_length-1).unsqueeze(0).expand(x.size(0), -1) # (B x T) Integers\n",
    "pos_indices = torch.where(x != padding_token, pos_indices, 0)\n",
    "fx = fx + position_embedding(pos_indices)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e1d0911e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0348,  1.1426, -0.8031, -0.8195, -0.3684,  1.2639, -1.4694,  1.0644,\n",
       "         0.8040, -0.7585,  1.0921,  0.1312,  1.0963, -0.6385,  0.1917,  0.5659,\n",
       "        -0.5897, -0.5680, -0.0359,  0.7629, -0.3593, -0.6200,  0.0919, -0.9852,\n",
       "        -1.3196,  0.8022,  0.7076, -0.4863,  0.3103,  0.6219, -1.3571,  0.3612,\n",
       "        -1.6877, -0.6480,  0.3568,  0.3413, -0.8393,  0.0097, -0.7561,  0.6869,\n",
       "        -0.8671, -0.1718, -1.2744,  0.3862,  2.6726, -1.4470, -1.9123, -0.9078,\n",
       "         0.8464,  1.8580,  0.9008,  0.1186, -0.3416, -1.2503,  1.6480, -0.2292,\n",
       "         0.3072,  0.8725,  0.3071,  0.5452, -0.2082, -0.1354, -0.9168,  0.8804,\n",
       "        -0.0058, -2.9138,  0.5338,  1.3497,  0.9038,  1.2460,  0.7885, -1.1703,\n",
       "        -0.6349,  0.1710, -1.4522, -0.6162,  0.1904, -1.1711,  0.7403, -0.0623,\n",
       "        -0.4848,  0.9151, -0.7054, -0.2913, -0.0721, -0.6024,  0.4909,  1.4899,\n",
       "         0.5611, -0.7335, -0.3828,  0.6754,  0.5060, -0.3605,  0.7011,  0.5704,\n",
       "         2.6185, -2.2117,  0.2219, -0.5261,  0.6317,  0.9382,  0.5390,  0.2139,\n",
       "        -0.0786, -1.0001, -0.4784,  0.4447,  0.8168, -1.6647,  0.3339, -0.2120,\n",
       "         0.9050, -0.0695,  0.1782, -0.5820, -0.2385,  1.1316, -0.3527, -1.4616,\n",
       "        -1.1235, -0.0643, -2.5572,  0.9054, -1.3865, -0.2003,  0.8390, -0.1142],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fx[0,-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19277ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Definition\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, vocab_size, num_heads, num_layers, dropout=0.1):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.context_length = context_length\n",
    "\n",
    "        # Token and positional embeddings\n",
    "        self.token_embedding = nn.Embedding(vocab_size, 128)\n",
    "        self.position_embedding = nn.Embedding(context_length, 128)\n",
    "\n",
    "        # Transformer decoder layers\n",
    "        self.decoder_layers = nn.ModuleList([\n",
    "            nn.TransformerDecoderLayer(d_model=128, nhead=num_heads, dropout=dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.layer_norm = nn.LayerNorm(128)\n",
    "\n",
    "        # Output projection\n",
    "        self.output_projection = nn.Linear(128, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, seq_len)\n",
    "        batch_size, seq_len = x.size()\n",
    "\n",
    "        # Token and positional embeddings\n",
    "        token_embeds = self.token_embedding(x)  # (batch_size, seq_len, embed_dim)\n",
    "        positions = torch.arange(seq_len, device=x.device).unsqueeze(0).expand(batch_size, seq_len)\n",
    "        position_embeds = self.position_embedding(positions)  # (batch_size, seq_len, embed_dim)\n",
    "\n",
    "        # Combine embeddings\n",
    "        embeddings = token_embeds + position_embeds  # (batch_size, seq_len, embed_dim)\n",
    "\n",
    "        # Prepare for Transformer decoder\n",
    "        embeddings = embeddings.permute(1, 0, 2)  # (seq_len, batch_size, embed_dim)\n",
    "\n",
    "        # Apply Transformer decoder layers\n",
    "        for layer in self.decoder_layers:\n",
    "            embeddings = layer(embeddings, memory=None)  # No memory for causal LM\n",
    "\n",
    "        # Apply layer normalization\n",
    "        embeddings = self.layer_norm(embeddings)  # (seq_len, batch_size, embed_dim)\n",
    "\n",
    "        # Project to vocabulary size\n",
    "        logits = self.output_projection(embeddings)  # (seq_len, batch_size, vocab_size)\n",
    "\n",
    "        return logits.permute(1, 0, 2)  # (batch_size, seq_len, vocab_size)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5914,
     "sourceId": 6944507,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11032.474625,
   "end_time": "2025-04-10T16:15:28.588659",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-10T13:11:36.114034",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
